Log file: results/cifar100/2021-12-02-10-20-05__densenet121_8077/log.txt
save path : results/cifar100/2021-12-02-10-20-05__densenet121_8077
torch version :1.8.2+cu111
python version :3.7.11 (default, Jul 27 2021, 14:32:16) 
[GCC 7.5.0]
Use Cuda :True
Dataset :cifar100
Network arch :densenet121
Batch size :128
Epochs :200
Random seed :8077
Num Workers :4
Lr Decay Steps size :60
Weight Decay :0.0005
Model :DenseNet(
  (features): Sequential(
    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu0): ReLU(inplace=True)
    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (denseblock1): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (transition1): _Transition(
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (denseblock2): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (transition2): _Transition(
      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (denseblock3): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer13): _DenseLayer(
        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer14): _DenseLayer(
        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer15): _DenseLayer(
        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer16): _DenseLayer(
        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer17): _DenseLayer(
        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer18): _DenseLayer(
        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer19): _DenseLayer(
        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer20): _DenseLayer(
        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer21): _DenseLayer(
        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer22): _DenseLayer(
        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer23): _DenseLayer(
        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer24): _DenseLayer(
        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (transition3): _Transition(
      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (denseblock4): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer13): _DenseLayer(
        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer14): _DenseLayer(
        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer15): _DenseLayer(
        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer16): _DenseLayer(
        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (classifier): Linear(in_features=1024, out_features=100, bias=True)
)
Optimizer : Adam
Epoch 0/199
----------
LR 0.001
train Loss: 3.4672 Acc: 0.1751
val Loss: 3.0360 Acc: 0.2377
saving best model
best_acc 0.2377
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 30s
Epoch 1/199
----------
LR 0.001
train Loss: 2.7230 Acc: 0.3018
val Loss: 2.7041 Acc: 0.3022
saving best model
best_acc 0.3022
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 30s
Epoch 2/199
----------
LR 0.001
train Loss: 2.3623 Acc: 0.3771
val Loss: 2.4084 Acc: 0.3692
saving best model
best_acc 0.3692
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 30s
Epoch 3/199
----------
LR 0.001
train Loss: 2.1094 Acc: 0.4360
val Loss: 2.2860 Acc: 0.3988
saving best model
best_acc 0.3988
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 30s
Epoch 4/199
----------
LR 0.001
train Loss: 1.9156 Acc: 0.4778
val Loss: 2.2384 Acc: 0.4145
saving best model
best_acc 0.4145
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 30s
Epoch 5/199
----------
LR 0.001
train Loss: 1.7516 Acc: 0.5159
val Loss: 2.0830 Acc: 0.4416
saving best model
best_acc 0.4416
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 30s
Epoch 6/199
----------
LR 0.001
train Loss: 1.6005 Acc: 0.5516
val Loss: 2.0641 Acc: 0.4560
saving best model
best_acc 0.456
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 30s
Epoch 7/199
----------
LR 0.001
train Loss: 1.4602 Acc: 0.5861
val Loss: 2.0624 Acc: 0.4569
saving best model
best_acc 0.4569
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 30s
Epoch 8/199
----------
LR 0.001
train Loss: 1.3246 Acc: 0.6187
val Loss: 2.0516 Acc: 0.4663
saving best model
best_acc 0.4663
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 30s
Epoch 9/199
----------
LR 0.001
train Loss: 1.2167 Acc: 0.6460
val Loss: 2.0616 Acc: 0.4690
saving best model
best_acc 0.469
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 30s
Epoch 10/199
----------
LR 0.001
train Loss: 1.0993 Acc: 0.6770
val Loss: 1.9923 Acc: 0.4839
saving best model
best_acc 0.4839
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 30s
Epoch 11/199
----------
LR 0.001
train Loss: 0.9874 Acc: 0.7083
val Loss: 1.9863 Acc: 0.4877
saving best model
best_acc 0.4877
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 30s
Epoch 12/199
----------
LR 0.001
train Loss: 0.8897 Acc: 0.7322
val Loss: 2.1102 Acc: 0.4734
0m 29s
Epoch 13/199
----------
LR 0.001
train Loss: 0.8050 Acc: 0.7566
val Loss: 2.1470 Acc: 0.4852
0m 29s
Epoch 14/199
----------
LR 0.001
train Loss: 0.7185 Acc: 0.7821
val Loss: 2.1145 Acc: 0.4906
saving best model
best_acc 0.4906
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 30s
Epoch 15/199
----------
LR 0.001
train Loss: 0.6610 Acc: 0.7967
val Loss: 2.1946 Acc: 0.4828
0m 29s
Epoch 16/199
----------
LR 0.001
train Loss: 0.6062 Acc: 0.8143
val Loss: 2.2157 Acc: 0.4911
saving best model
best_acc 0.4911
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 30s
Epoch 17/199
----------
LR 0.001
train Loss: 0.5461 Acc: 0.8325
val Loss: 2.3583 Acc: 0.4756
0m 29s
Epoch 18/199
----------
LR 0.001
train Loss: 0.5162 Acc: 0.8390
val Loss: 2.2692 Acc: 0.4873
0m 29s
Epoch 19/199
----------
LR 0.001
train Loss: 0.4756 Acc: 0.8536
val Loss: 2.3615 Acc: 0.4713
0m 29s
Epoch 20/199
----------
LR 0.001
train Loss: 0.4577 Acc: 0.8588
val Loss: 2.3534 Acc: 0.4806
0m 29s
Epoch 21/199
----------
LR 0.001
train Loss: 0.4401 Acc: 0.8649
val Loss: 2.4400 Acc: 0.4749
0m 29s
Epoch 22/199
----------
LR 0.001
train Loss: 0.4167 Acc: 0.8719
val Loss: 2.4194 Acc: 0.4732
0m 29s
Epoch 23/199
----------
LR 0.001
train Loss: 0.4054 Acc: 0.8739
val Loss: 2.4232 Acc: 0.4837
0m 29s
Epoch 24/199
----------
LR 0.001
train Loss: 0.4025 Acc: 0.8744
val Loss: 2.5377 Acc: 0.4606
0m 30s
Epoch 25/199
----------
LR 0.001
train Loss: 0.3714 Acc: 0.8878
val Loss: 2.4123 Acc: 0.4836
0m 29s
Epoch 26/199
----------
LR 0.001
train Loss: 0.3784 Acc: 0.8831
val Loss: 2.4906 Acc: 0.4709
0m 30s
Epoch 27/199
----------
LR 0.001
train Loss: 0.3677 Acc: 0.8872
val Loss: 2.4212 Acc: 0.4777
0m 30s
Epoch 28/199
----------
LR 0.001
train Loss: 0.3558 Acc: 0.8902
val Loss: 2.5480 Acc: 0.4713
0m 29s
Epoch 29/199
----------
LR 0.001
train Loss: 0.3585 Acc: 0.8892
val Loss: 2.5095 Acc: 0.4753
0m 29s
Epoch 30/199
----------
LR 0.001
train Loss: 0.3353 Acc: 0.8983
val Loss: 2.5564 Acc: 0.4666
0m 29s
Epoch 31/199
----------
LR 0.001
train Loss: 0.3547 Acc: 0.8918
val Loss: 2.4877 Acc: 0.4777
0m 30s
Epoch 32/199
----------
LR 0.001
train Loss: 0.3307 Acc: 0.8983
val Loss: 2.5334 Acc: 0.4714
0m 30s
Epoch 33/199
----------
LR 0.001
train Loss: 0.3289 Acc: 0.9002
val Loss: 2.4773 Acc: 0.4815
0m 29s
Epoch 34/199
----------
LR 0.001
train Loss: 0.3475 Acc: 0.8935
val Loss: 2.5112 Acc: 0.4750
0m 29s
Epoch 35/199
----------
LR 0.001
train Loss: 0.3296 Acc: 0.8986
val Loss: 2.5074 Acc: 0.4721
0m 29s
Epoch 36/199
----------
LR 0.001
train Loss: 0.3326 Acc: 0.8979
val Loss: 2.4781 Acc: 0.4807
0m 29s
Epoch 37/199
----------
LR 0.001
train Loss: 0.3294 Acc: 0.8988
val Loss: 2.5550 Acc: 0.4675
0m 29s
Epoch 38/199
----------
LR 0.001
train Loss: 0.3268 Acc: 0.9001
val Loss: 2.4947 Acc: 0.4708
0m 30s
Epoch 39/199
----------
LR 0.001
train Loss: 0.3016 Acc: 0.9089
val Loss: 2.5519 Acc: 0.4695
0m 29s
Epoch 40/199
----------
LR 0.001
train Loss: 0.3144 Acc: 0.9047
val Loss: 2.4887 Acc: 0.4768
0m 29s
Epoch 41/199
----------
LR 0.001
train Loss: 0.3108 Acc: 0.9056
val Loss: 2.4701 Acc: 0.4796
0m 29s
Epoch 42/199
----------
LR 0.001
train Loss: 0.3234 Acc: 0.9022
val Loss: 2.5130 Acc: 0.4787
0m 29s
Epoch 43/199
----------
LR 0.001
train Loss: 0.3061 Acc: 0.9069
val Loss: 2.6495 Acc: 0.4624
0m 29s
Epoch 44/199
----------
LR 0.001
train Loss: 0.3049 Acc: 0.9066
val Loss: 2.5729 Acc: 0.4719
0m 30s
Epoch 45/199
----------
LR 0.001
train Loss: 0.3051 Acc: 0.9063
val Loss: 2.6106 Acc: 0.4675
0m 29s
Epoch 46/199
----------
LR 0.001
train Loss: 0.3244 Acc: 0.9003
val Loss: 2.5187 Acc: 0.4760
0m 29s
Epoch 47/199
----------
LR 0.001
train Loss: 0.2715 Acc: 0.9192
val Loss: 2.5560 Acc: 0.4678
0m 29s
Epoch 48/199
----------
LR 0.001
train Loss: 0.3126 Acc: 0.9050
val Loss: 2.5928 Acc: 0.4689
0m 29s
Epoch 49/199
----------
LR 0.001
train Loss: 0.3199 Acc: 0.9010
val Loss: 2.5559 Acc: 0.4794
0m 29s
Epoch 50/199
----------
LR 0.001
train Loss: 0.2767 Acc: 0.9177
val Loss: 2.5536 Acc: 0.4770
0m 29s
Epoch 51/199
----------
LR 0.001
train Loss: 0.2958 Acc: 0.9083
val Loss: 2.5458 Acc: 0.4792
0m 30s
Epoch 52/199
----------
LR 0.001
train Loss: 0.3210 Acc: 0.9020
val Loss: 2.5904 Acc: 0.4773
0m 29s
Epoch 53/199
----------
LR 0.001
train Loss: 0.2679 Acc: 0.9204
val Loss: 2.5825 Acc: 0.4707
0m 30s
Epoch 54/199
----------
LR 0.001
train Loss: 0.2958 Acc: 0.9104
val Loss: 2.6798 Acc: 0.4671
0m 30s
Epoch 55/199
----------
LR 0.001
train Loss: 0.3069 Acc: 0.9068
val Loss: 2.5548 Acc: 0.4735
0m 29s
Epoch 56/199
----------
LR 0.001
train Loss: 0.2779 Acc: 0.9152
val Loss: 2.5828 Acc: 0.4694
0m 29s
Epoch 57/199
----------
LR 0.001
train Loss: 0.2844 Acc: 0.9137
val Loss: 2.5557 Acc: 0.4823
0m 29s
Epoch 58/199
----------
LR 0.001
train Loss: 0.2879 Acc: 0.9132
val Loss: 2.6304 Acc: 0.4691
0m 29s
Epoch 59/199
----------
LR 0.001
train Loss: 0.2830 Acc: 0.9161
val Loss: 2.6144 Acc: 0.4675
0m 29s
Epoch 60/199
----------
LR 0.0002
train Loss: 0.1071 Acc: 0.9749
val Loss: 2.2450 Acc: 0.5235
saving best model
best_acc 0.5235
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 30s
Epoch 61/199
----------
LR 0.0002
train Loss: 0.0292 Acc: 0.9986
val Loss: 2.2263 Acc: 0.5270
saving best model
best_acc 0.527
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 30s
Epoch 62/199
----------
LR 0.0002
train Loss: 0.0209 Acc: 0.9994
val Loss: 2.1978 Acc: 0.5269
0m 29s
Epoch 63/199
----------
LR 0.0002
train Loss: 0.0174 Acc: 0.9994
val Loss: 2.1848 Acc: 0.5283
saving best model
best_acc 0.5283
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 30s
Epoch 64/199
----------
LR 0.0002
train Loss: 0.0164 Acc: 0.9994
val Loss: 2.1617 Acc: 0.5258
0m 29s
Epoch 65/199
----------
LR 0.0002
train Loss: 0.0162 Acc: 0.9995
val Loss: 2.1287 Acc: 0.5267
0m 30s
Epoch 66/199
----------
LR 0.0002
train Loss: 0.0162 Acc: 0.9995
val Loss: 2.1142 Acc: 0.5255
0m 29s
Epoch 67/199
----------
LR 0.0002
train Loss: 0.0179 Acc: 0.9993
val Loss: 2.0844 Acc: 0.5259
0m 29s
Epoch 68/199
----------
LR 0.0002
train Loss: 0.0180 Acc: 0.9994
val Loss: 2.1241 Acc: 0.5209
0m 30s
Epoch 69/199
----------
LR 0.0002
train Loss: 0.0195 Acc: 0.9994
val Loss: 2.1039 Acc: 0.5212
0m 30s
Epoch 70/199
----------
LR 0.0002
train Loss: 0.0219 Acc: 0.9992
val Loss: 2.1305 Acc: 0.5157
0m 29s
Epoch 71/199
----------
LR 0.0002
train Loss: 0.0291 Acc: 0.9986
val Loss: 2.1999 Acc: 0.5051
0m 30s
Epoch 72/199
----------
LR 0.0002
train Loss: 0.0590 Acc: 0.9932
val Loss: 2.3595 Acc: 0.4900
0m 29s
Epoch 73/199
----------
LR 0.0002
train Loss: 0.0471 Acc: 0.9947
val Loss: 2.2777 Acc: 0.5054
0m 30s
Epoch 74/199
----------
LR 0.0002
train Loss: 0.0212 Acc: 0.9987
val Loss: 2.2168 Acc: 0.5108
0m 30s
Epoch 75/199
----------
LR 0.0002
train Loss: 0.0150 Acc: 0.9993
val Loss: 2.1697 Acc: 0.5159
0m 29s
Epoch 76/199
----------
LR 0.0002
train Loss: 0.0145 Acc: 0.9994
val Loss: 2.1341 Acc: 0.5166
0m 30s
Epoch 77/199
----------
LR 0.0002
train Loss: 0.0147 Acc: 0.9995
val Loss: 2.1494 Acc: 0.5124
0m 29s
Epoch 78/199
----------
LR 0.0002
train Loss: 0.0325 Acc: 0.9971
val Loss: 2.4574 Acc: 0.4663
0m 30s
Epoch 79/199
----------
LR 0.0002
train Loss: 0.1695 Acc: 0.9601
val Loss: 2.3850 Acc: 0.4943
0m 30s
Epoch 80/199
----------
LR 0.0002
train Loss: 0.0379 Acc: 0.9954
val Loss: 2.2840 Acc: 0.5063
0m 29s
Epoch 81/199
----------
LR 0.0002
train Loss: 0.0163 Acc: 0.9992
val Loss: 2.2304 Acc: 0.5087
0m 29s
Epoch 82/199
----------
LR 0.0002
train Loss: 0.0122 Acc: 0.9995
val Loss: 2.1939 Acc: 0.5109
0m 29s
Epoch 83/199
----------
LR 0.0002
train Loss: 0.0118 Acc: 0.9994
val Loss: 2.1677 Acc: 0.5128
0m 30s
Epoch 84/199
----------
LR 0.0002
train Loss: 0.0123 Acc: 0.9996
val Loss: 2.1585 Acc: 0.5157
0m 29s
Epoch 85/199
----------
LR 0.0002
train Loss: 0.0138 Acc: 0.9995
val Loss: 2.1643 Acc: 0.5081
0m 30s
Epoch 86/199
----------
LR 0.0002
train Loss: 0.1575 Acc: 0.9605
val Loss: 2.4149 Acc: 0.4796
0m 29s
Epoch 87/199
----------
LR 0.0002
train Loss: 0.1083 Acc: 0.9763
val Loss: 2.3795 Acc: 0.4966
0m 30s
Epoch 88/199
----------
LR 0.0002
train Loss: 0.0319 Acc: 0.9962
val Loss: 2.3275 Acc: 0.5014
0m 29s
Epoch 89/199
----------
LR 0.0002
train Loss: 0.0169 Acc: 0.9990
val Loss: 2.2838 Acc: 0.5120
0m 29s
Epoch 90/199
----------
LR 0.0002
train Loss: 0.0129 Acc: 0.9992
val Loss: 2.2669 Acc: 0.5106
0m 30s
Epoch 91/199
----------
LR 0.0002
train Loss: 0.0116 Acc: 0.9994
val Loss: 2.2328 Acc: 0.5083
0m 30s
Epoch 92/199
----------
LR 0.0002
train Loss: 0.0124 Acc: 0.9995
val Loss: 2.2550 Acc: 0.5054
0m 30s
Epoch 93/199
----------
LR 0.0002
train Loss: 0.0399 Acc: 0.9944
val Loss: 2.6087 Acc: 0.4504
0m 29s
Epoch 94/199
----------
LR 0.0002
train Loss: 0.2052 Acc: 0.9465
val Loss: 2.4166 Acc: 0.4878
0m 29s
Epoch 95/199
----------
LR 0.0002
train Loss: 0.0510 Acc: 0.9911
val Loss: 2.3691 Acc: 0.5063
0m 29s
Epoch 96/199
----------
LR 0.0002
train Loss: 0.0220 Acc: 0.9976
val Loss: 2.3218 Acc: 0.5147
0m 29s
Epoch 97/199
----------
LR 0.0002
train Loss: 0.0151 Acc: 0.9990
val Loss: 2.2905 Acc: 0.5122
0m 30s
Epoch 98/199
----------
LR 0.0002
train Loss: 0.0118 Acc: 0.9995
val Loss: 2.2540 Acc: 0.5156
0m 29s
Epoch 99/199
----------
LR 0.0002
train Loss: 0.0126 Acc: 0.9994
val Loss: 2.2815 Acc: 0.5088
0m 29s
Epoch 100/199
----------
LR 0.0002
train Loss: 0.0160 Acc: 0.9989
val Loss: 2.3367 Acc: 0.4978
0m 29s
Epoch 101/199
----------
LR 0.0002
train Loss: 0.1929 Acc: 0.9480
val Loss: 2.5186 Acc: 0.4772
0m 29s
Epoch 102/199
----------
LR 0.0002
train Loss: 0.1070 Acc: 0.9740
val Loss: 2.4394 Acc: 0.4965
0m 29s
Epoch 103/199
----------
LR 0.0002
train Loss: 0.0369 Acc: 0.9944
val Loss: 2.4146 Acc: 0.5000
0m 29s
Epoch 104/199
----------
LR 0.0002
train Loss: 0.0192 Acc: 0.9981
val Loss: 2.3801 Acc: 0.5064
0m 29s
Epoch 105/199
----------
LR 0.0002
train Loss: 0.0139 Acc: 0.9991
val Loss: 2.3756 Acc: 0.5058
0m 29s
Epoch 106/199
----------
LR 0.0002
train Loss: 0.0135 Acc: 0.9990
val Loss: 2.3566 Acc: 0.5057
0m 29s
Epoch 107/199
----------
LR 0.0002
train Loss: 0.0157 Acc: 0.9991
val Loss: 2.3953 Acc: 0.5027
0m 29s
Epoch 108/199
----------
LR 0.0002
train Loss: 0.1300 Acc: 0.9669
val Loss: 2.5934 Acc: 0.4678
0m 30s
Epoch 109/199
----------
LR 0.0002
train Loss: 0.1407 Acc: 0.9640
val Loss: 2.4898 Acc: 0.4948
0m 29s
Epoch 110/199
----------
LR 0.0002
train Loss: 0.0428 Acc: 0.9922
val Loss: 2.4228 Acc: 0.5087
0m 30s
Epoch 111/199
----------
LR 0.0002
train Loss: 0.0217 Acc: 0.9975
val Loss: 2.4132 Acc: 0.5057
0m 29s
Epoch 112/199
----------
LR 0.0002
train Loss: 0.0156 Acc: 0.9985
val Loss: 2.4060 Acc: 0.5064
0m 29s
Epoch 113/199
----------
LR 0.0002
train Loss: 0.0165 Acc: 0.9985
val Loss: 2.4049 Acc: 0.5053
0m 29s
Epoch 114/199
----------
LR 0.0002
train Loss: 0.0223 Acc: 0.9973
val Loss: 2.5370 Acc: 0.4882
0m 29s
Epoch 115/199
----------
LR 0.0002
train Loss: 0.1577 Acc: 0.9578
val Loss: 2.5490 Acc: 0.4817
0m 29s
Epoch 116/199
----------
LR 0.0002
train Loss: 0.0948 Acc: 0.9765
val Loss: 2.4671 Acc: 0.5032
0m 30s
Epoch 117/199
----------
LR 0.0002
train Loss: 0.0384 Acc: 0.9931
val Loss: 2.4548 Acc: 0.5020
0m 29s
Epoch 118/199
----------
LR 0.0002
train Loss: 0.0238 Acc: 0.9966
val Loss: 2.4584 Acc: 0.5042
0m 30s
Epoch 119/199
----------
LR 0.0002
train Loss: 0.0199 Acc: 0.9978
val Loss: 2.4766 Acc: 0.4989
0m 29s
Epoch 120/199
----------
LR 4e-05
train Loss: 0.0130 Acc: 0.9991
val Loss: 2.3971 Acc: 0.5105
0m 29s
Epoch 121/199
----------
LR 4e-05
train Loss: 0.0087 Acc: 0.9996
val Loss: 2.3774 Acc: 0.5149
0m 30s
Epoch 122/199
----------
LR 4e-05
train Loss: 0.0079 Acc: 0.9997
val Loss: 2.3696 Acc: 0.5147
0m 29s
Epoch 123/199
----------
LR 4e-05
train Loss: 0.0079 Acc: 0.9996
val Loss: 2.3373 Acc: 0.5180
0m 29s
Epoch 124/199
----------
LR 4e-05
train Loss: 0.0079 Acc: 0.9996
val Loss: 2.3362 Acc: 0.5158
0m 30s
Epoch 125/199
----------
LR 4e-05
train Loss: 0.0078 Acc: 0.9996
val Loss: 2.3240 Acc: 0.5163
0m 29s
Epoch 126/199
----------
LR 4e-05
train Loss: 0.0078 Acc: 0.9997
val Loss: 2.3058 Acc: 0.5147
0m 29s
Epoch 127/199
----------
LR 4e-05
train Loss: 0.0079 Acc: 0.9997
val Loss: 2.2982 Acc: 0.5182
0m 29s
Epoch 128/199
----------
LR 4e-05
train Loss: 0.0083 Acc: 0.9996
val Loss: 2.2852 Acc: 0.5189
0m 29s
Epoch 129/199
----------
LR 4e-05
train Loss: 0.0086 Acc: 0.9997
val Loss: 2.2864 Acc: 0.5181
0m 29s
Epoch 130/199
----------
LR 4e-05
train Loss: 0.0087 Acc: 0.9997
val Loss: 2.2810 Acc: 0.5177
0m 29s
Epoch 131/199
----------
LR 4e-05
train Loss: 0.0090 Acc: 0.9997
val Loss: 2.2940 Acc: 0.5154
0m 29s
Epoch 132/199
----------
LR 4e-05
train Loss: 0.0094 Acc: 0.9996
val Loss: 2.2898 Acc: 0.5128
0m 30s
Epoch 133/199
----------
LR 4e-05
train Loss: 0.0097 Acc: 0.9997
val Loss: 2.3098 Acc: 0.5129
0m 29s
Epoch 134/199
----------
LR 4e-05
train Loss: 0.0097 Acc: 0.9997
val Loss: 2.3248 Acc: 0.5097
0m 29s
Epoch 135/199
----------
LR 4e-05
train Loss: 0.0102 Acc: 0.9996
val Loss: 2.3190 Acc: 0.5116
0m 30s
Epoch 136/199
----------
LR 4e-05
train Loss: 0.0105 Acc: 0.9995
val Loss: 2.3542 Acc: 0.5089
0m 30s
Epoch 137/199
----------
LR 4e-05
train Loss: 0.0116 Acc: 0.9992
val Loss: 2.3518 Acc: 0.5088
0m 29s
Epoch 138/199
----------
LR 4e-05
train Loss: 0.0102 Acc: 0.9995
val Loss: 2.3483 Acc: 0.5095
0m 29s
Epoch 139/199
----------
LR 4e-05
train Loss: 0.0101 Acc: 0.9995
val Loss: 2.3647 Acc: 0.5096
0m 29s
Epoch 140/199
----------
LR 4e-05
train Loss: 0.0099 Acc: 0.9995
val Loss: 2.3583 Acc: 0.5127
0m 29s
Epoch 141/199
----------
LR 4e-05
train Loss: 0.0095 Acc: 0.9996
val Loss: 2.3604 Acc: 0.5163
0m 29s
Epoch 142/199
----------
LR 4e-05
train Loss: 0.0100 Acc: 0.9996
val Loss: 2.3960 Acc: 0.5092
0m 29s
Epoch 143/199
----------
LR 4e-05
train Loss: 0.0098 Acc: 0.9997
val Loss: 2.3952 Acc: 0.5103
0m 30s
Epoch 144/199
----------
LR 4e-05
train Loss: 0.0098 Acc: 0.9997
val Loss: 2.4315 Acc: 0.5020
0m 29s
Epoch 145/199
----------
LR 4e-05
train Loss: 0.0101 Acc: 0.9996
val Loss: 2.4150 Acc: 0.5086
0m 29s
Epoch 146/199
----------
LR 4e-05
train Loss: 0.0094 Acc: 0.9996
val Loss: 2.4148 Acc: 0.5100
0m 29s
Epoch 147/199
----------
LR 4e-05
train Loss: 0.0095 Acc: 0.9996
val Loss: 2.4407 Acc: 0.5090
0m 30s
Epoch 148/199
----------
LR 4e-05
train Loss: 0.0113 Acc: 0.9994
val Loss: 2.4789 Acc: 0.5045
0m 30s
Epoch 149/199
----------
LR 4e-05
train Loss: 0.0113 Acc: 0.9993
val Loss: 2.4617 Acc: 0.5033
0m 29s
Epoch 150/199
----------
LR 4e-05
train Loss: 0.0111 Acc: 0.9994
val Loss: 2.5153 Acc: 0.5008
0m 29s
Epoch 151/199
----------
LR 4e-05
train Loss: 0.0101 Acc: 0.9995
val Loss: 2.4777 Acc: 0.5044
0m 30s
Epoch 152/199
----------
LR 4e-05
train Loss: 0.0095 Acc: 0.9996
val Loss: 2.4791 Acc: 0.5061
0m 30s
Epoch 153/199
----------
LR 4e-05
train Loss: 0.0094 Acc: 0.9996
val Loss: 2.4996 Acc: 0.5020
0m 29s
Epoch 154/199
----------
LR 4e-05
train Loss: 0.0096 Acc: 0.9996
val Loss: 2.4940 Acc: 0.5058
0m 29s
Epoch 155/199
----------
LR 4e-05
train Loss: 0.0093 Acc: 0.9997
val Loss: 2.4973 Acc: 0.5040
0m 29s
Epoch 156/199
----------
LR 4e-05
train Loss: 0.0099 Acc: 0.9995
val Loss: 2.5175 Acc: 0.5024
0m 30s
Epoch 157/199
----------
LR 4e-05
train Loss: 0.0091 Acc: 0.9997
val Loss: 2.5190 Acc: 0.5052
0m 29s
Epoch 158/199
----------
LR 4e-05
train Loss: 0.0125 Acc: 0.9990
val Loss: 2.5799 Acc: 0.4999
0m 29s
Epoch 159/199
----------
LR 4e-05
train Loss: 0.0162 Acc: 0.9983
val Loss: 2.5980 Acc: 0.4947
0m 29s
Epoch 160/199
----------
LR 4e-05
train Loss: 0.0125 Acc: 0.9989
val Loss: 2.5942 Acc: 0.4990
0m 30s
Epoch 161/199
----------
LR 4e-05
train Loss: 0.0104 Acc: 0.9995
val Loss: 2.5941 Acc: 0.5017
0m 29s
Epoch 162/199
----------
LR 4e-05
train Loss: 0.0096 Acc: 0.9996
val Loss: 2.5789 Acc: 0.5018
0m 29s
Epoch 163/199
----------
LR 4e-05
train Loss: 0.0108 Acc: 0.9992
val Loss: 2.5907 Acc: 0.5002
0m 29s
Epoch 164/199
----------
LR 4e-05
train Loss: 0.0120 Acc: 0.9990
val Loss: 2.6203 Acc: 0.4953
0m 29s
Epoch 165/199
----------
LR 4e-05
train Loss: 0.0108 Acc: 0.9993
val Loss: 2.6115 Acc: 0.4976
0m 29s
Epoch 166/199
----------
LR 4e-05
train Loss: 0.0113 Acc: 0.9991
val Loss: 2.6109 Acc: 0.4958
0m 29s
Epoch 167/199
----------
LR 4e-05
train Loss: 0.0112 Acc: 0.9992
val Loss: 2.6333 Acc: 0.4940
0m 30s
Epoch 168/199
----------
LR 4e-05
train Loss: 0.0098 Acc: 0.9995
val Loss: 2.6144 Acc: 0.4969
0m 30s
Epoch 169/199
----------
LR 4e-05
train Loss: 0.0092 Acc: 0.9995
val Loss: 2.6123 Acc: 0.5037
0m 30s
Epoch 170/199
----------
LR 4e-05
train Loss: 0.0107 Acc: 0.9995
val Loss: 2.6596 Acc: 0.4924
0m 30s
Epoch 171/199
----------
LR 4e-05
train Loss: 0.0106 Acc: 0.9993
val Loss: 2.6469 Acc: 0.4927
0m 30s
Epoch 172/199
----------
LR 4e-05
train Loss: 0.0114 Acc: 0.9993
val Loss: 2.6669 Acc: 0.4946
0m 30s
Epoch 173/199
----------
LR 4e-05
train Loss: 0.0109 Acc: 0.9993
val Loss: 2.6763 Acc: 0.4951
0m 30s
Epoch 174/199
----------
LR 4e-05
train Loss: 0.0115 Acc: 0.9992
val Loss: 2.6798 Acc: 0.4957
0m 29s
Epoch 175/199
----------
LR 4e-05
train Loss: 0.0103 Acc: 0.9994
val Loss: 2.7088 Acc: 0.4920
0m 29s
Epoch 176/199
----------
LR 4e-05
train Loss: 0.0110 Acc: 0.9993
val Loss: 2.6930 Acc: 0.4957
0m 29s
Epoch 177/199
----------
LR 4e-05
train Loss: 0.0096 Acc: 0.9994
val Loss: 2.6755 Acc: 0.4929
0m 29s
Epoch 178/199
----------
LR 4e-05
train Loss: 0.0113 Acc: 0.9991
val Loss: 2.7099 Acc: 0.4933
0m 30s
Epoch 179/199
----------
LR 4e-05
train Loss: 0.0121 Acc: 0.9991
val Loss: 2.7418 Acc: 0.4916
0m 29s
Epoch 180/199
----------
LR 8.000000000000001e-06
train Loss: 0.0108 Acc: 0.9991
val Loss: 2.7272 Acc: 0.4946
0m 29s
Epoch 181/199
----------
LR 8.000000000000001e-06
train Loss: 0.0094 Acc: 0.9995
val Loss: 2.7056 Acc: 0.4952
0m 29s
Epoch 182/199
----------
LR 8.000000000000001e-06
train Loss: 0.0087 Acc: 0.9996
val Loss: 2.6864 Acc: 0.4962
0m 29s
Epoch 183/199
----------
LR 8.000000000000001e-06
train Loss: 0.0082 Acc: 0.9996
val Loss: 2.6882 Acc: 0.4956
0m 30s
Epoch 184/199
----------
LR 8.000000000000001e-06
train Loss: 0.0079 Acc: 0.9997
val Loss: 2.6807 Acc: 0.4959
0m 29s
Epoch 185/199
----------
LR 8.000000000000001e-06
train Loss: 0.0079 Acc: 0.9997
val Loss: 2.6743 Acc: 0.4976
0m 29s
Epoch 186/199
----------
LR 8.000000000000001e-06
train Loss: 0.0076 Acc: 0.9998
val Loss: 2.6736 Acc: 0.4984
0m 29s
Epoch 187/199
----------
LR 8.000000000000001e-06
train Loss: 0.0074 Acc: 0.9998
val Loss: 2.6686 Acc: 0.4988
0m 30s
Epoch 188/199
----------
LR 8.000000000000001e-06
train Loss: 0.0074 Acc: 0.9998
val Loss: 2.6586 Acc: 0.5001
0m 29s
Epoch 189/199
----------
LR 8.000000000000001e-06
train Loss: 0.0075 Acc: 0.9997
val Loss: 2.6507 Acc: 0.5006
0m 29s
Epoch 190/199
----------
LR 8.000000000000001e-06
train Loss: 0.0073 Acc: 0.9998
val Loss: 2.6485 Acc: 0.4996
0m 29s
Epoch 191/199
----------
LR 8.000000000000001e-06
train Loss: 0.0076 Acc: 0.9997
val Loss: 2.6495 Acc: 0.5006
0m 30s
Epoch 192/199
----------
LR 8.000000000000001e-06
train Loss: 0.0075 Acc: 0.9997
val Loss: 2.6425 Acc: 0.5014
0m 30s
Epoch 193/199
----------
LR 8.000000000000001e-06
train Loss: 0.0073 Acc: 0.9998
val Loss: 2.6421 Acc: 0.5007
0m 30s
Epoch 194/199
----------
LR 8.000000000000001e-06
train Loss: 0.0075 Acc: 0.9998
val Loss: 2.6443 Acc: 0.4992
0m 29s
Epoch 195/199
----------
LR 8.000000000000001e-06
train Loss: 0.0075 Acc: 0.9997
val Loss: 2.6377 Acc: 0.4988
0m 30s
Epoch 196/199
----------
LR 8.000000000000001e-06
train Loss: 0.0075 Acc: 0.9997
val Loss: 2.6475 Acc: 0.4983
0m 29s
Epoch 197/199
----------
LR 8.000000000000001e-06
train Loss: 0.0074 Acc: 0.9997
val Loss: 2.6335 Acc: 0.4997
0m 30s
Epoch 198/199
----------
LR 8.000000000000001e-06
train Loss: 0.0073 Acc: 0.9998
val Loss: 2.6380 Acc: 0.5006
0m 30s
Epoch 199/199
----------
LR 8.000000000000001e-06
train Loss: 0.0074 Acc: 0.9998
val Loss: 2.6437 Acc: 0.4959
0m 30s
Best val acc: 0.528300
Model :DenseNet(
  (features): Sequential(
    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu0): ReLU(inplace=True)
    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (denseblock1): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (transition1): _Transition(
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (denseblock2): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (transition2): _Transition(
      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (denseblock3): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer13): _DenseLayer(
        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer14): _DenseLayer(
        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer15): _DenseLayer(
        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer16): _DenseLayer(
        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer17): _DenseLayer(
        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer18): _DenseLayer(
        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer19): _DenseLayer(
        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer20): _DenseLayer(
        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer21): _DenseLayer(
        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer22): _DenseLayer(
        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer23): _DenseLayer(
        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer24): _DenseLayer(
        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (transition3): _Transition(
      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (denseblock4): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer13): _DenseLayer(
        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer14): _DenseLayer(
        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer15): _DenseLayer(
        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer16): _DenseLayer(
        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (classifier): Linear(in_features=1024, out_features=100, bias=True)
)
Optimizer : Adamomentum
Epoch 0/199
----------
LR 0.001
train Loss: 3.6968 Acc: 0.1409
val Loss: 3.2350 Acc: 0.2050
saving best model
best_acc 0.205
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 1/199
----------
LR 0.001
train Loss: 2.8918 Acc: 0.2733
val Loss: 2.7447 Acc: 0.2968
saving best model
best_acc 0.2968
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 2/199
----------
LR 0.001
train Loss: 2.4493 Acc: 0.3597
val Loss: 2.4956 Acc: 0.3515
saving best model
best_acc 0.3515
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 3/199
----------
LR 0.001
train Loss: 2.1345 Acc: 0.4294
val Loss: 2.3550 Acc: 0.3885
saving best model
best_acc 0.3885
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 4/199
----------
LR 0.001
train Loss: 1.8889 Acc: 0.4836
val Loss: 2.3185 Acc: 0.4019
saving best model
best_acc 0.4019
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 5/199
----------
LR 0.001
train Loss: 1.6829 Acc: 0.5329
val Loss: 2.2044 Acc: 0.4306
saving best model
best_acc 0.4306
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 6/199
----------
LR 0.001
train Loss: 1.5094 Acc: 0.5773
val Loss: 2.1532 Acc: 0.4426
saving best model
best_acc 0.4426
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 7/199
----------
LR 0.001
train Loss: 1.3555 Acc: 0.6127
val Loss: 2.1309 Acc: 0.4482
saving best model
best_acc 0.4482
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 8/199
----------
LR 0.001
train Loss: 1.2272 Acc: 0.6450
val Loss: 2.1627 Acc: 0.4494
saving best model
best_acc 0.4494
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 9/199
----------
LR 0.001
train Loss: 1.1040 Acc: 0.6756
val Loss: 2.1979 Acc: 0.4540
saving best model
best_acc 0.454
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 10/199
----------
LR 0.001
train Loss: 1.0072 Acc: 0.7010
val Loss: 2.2103 Acc: 0.4591
saving best model
best_acc 0.4591
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 11/199
----------
LR 0.001
train Loss: 0.9098 Acc: 0.7274
val Loss: 2.1689 Acc: 0.4695
saving best model
best_acc 0.4695
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 12/199
----------
LR 0.001
train Loss: 0.8217 Acc: 0.7531
val Loss: 2.1995 Acc: 0.4643
0m 30s
Epoch 13/199
----------
LR 0.001
train Loss: 0.7404 Acc: 0.7745
val Loss: 2.3326 Acc: 0.4572
0m 30s
Epoch 14/199
----------
LR 0.001
train Loss: 0.6963 Acc: 0.7876
val Loss: 2.3025 Acc: 0.4682
0m 30s
Epoch 15/199
----------
LR 0.001
train Loss: 0.6298 Acc: 0.8072
val Loss: 2.3721 Acc: 0.4616
0m 31s
Epoch 16/199
----------
LR 0.001
train Loss: 0.5917 Acc: 0.8166
val Loss: 2.3553 Acc: 0.4668
0m 30s
Epoch 17/199
----------
LR 0.001
train Loss: 0.5554 Acc: 0.8296
val Loss: 2.4323 Acc: 0.4594
0m 30s
Epoch 18/199
----------
LR 0.001
train Loss: 0.5324 Acc: 0.8334
val Loss: 2.4036 Acc: 0.4620
0m 30s
Epoch 19/199
----------
LR 0.001
train Loss: 0.4976 Acc: 0.8450
val Loss: 2.4252 Acc: 0.4678
0m 31s
Epoch 20/199
----------
LR 0.001
train Loss: 0.4658 Acc: 0.8565
val Loss: 2.4213 Acc: 0.4709
saving best model
best_acc 0.4709
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 21/199
----------
LR 0.001
train Loss: 0.4578 Acc: 0.8574
val Loss: 2.4144 Acc: 0.4702
0m 30s
Epoch 22/199
----------
LR 0.001
train Loss: 0.4608 Acc: 0.8564
val Loss: 2.4419 Acc: 0.4638
0m 30s
Epoch 23/199
----------
LR 0.001
train Loss: 0.4387 Acc: 0.8639
val Loss: 2.5278 Acc: 0.4574
0m 30s
Epoch 24/199
----------
LR 0.001
train Loss: 0.4305 Acc: 0.8659
val Loss: 2.5493 Acc: 0.4594
0m 31s
Epoch 25/199
----------
LR 0.001
train Loss: 0.4124 Acc: 0.8719
val Loss: 2.5483 Acc: 0.4602
0m 30s
Epoch 26/199
----------
LR 0.001
train Loss: 0.4220 Acc: 0.8696
val Loss: 2.5211 Acc: 0.4623
0m 31s
Epoch 27/199
----------
LR 0.001
train Loss: 0.3919 Acc: 0.8789
val Loss: 2.5395 Acc: 0.4618
0m 31s
Epoch 28/199
----------
LR 0.001
train Loss: 0.3874 Acc: 0.8809
val Loss: 2.5408 Acc: 0.4611
0m 31s
Epoch 29/199
----------
LR 0.001
train Loss: 0.4133 Acc: 0.8724
val Loss: 2.5056 Acc: 0.4603
0m 30s
Epoch 30/199
----------
LR 0.001
train Loss: 0.3865 Acc: 0.8808
val Loss: 2.5191 Acc: 0.4600
0m 30s
Epoch 31/199
----------
LR 0.001
train Loss: 0.3812 Acc: 0.8828
val Loss: 2.4763 Acc: 0.4705
0m 31s
Epoch 32/199
----------
LR 0.001
train Loss: 0.3646 Acc: 0.8886
val Loss: 2.4998 Acc: 0.4760
saving best model
best_acc 0.476
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 33/199
----------
LR 0.001
train Loss: 0.3944 Acc: 0.8798
val Loss: 2.4571 Acc: 0.4711
0m 31s
Epoch 34/199
----------
LR 0.001
train Loss: 0.3818 Acc: 0.8827
val Loss: 2.4911 Acc: 0.4657
0m 31s
Epoch 35/199
----------
LR 0.001
train Loss: 0.3964 Acc: 0.8784
val Loss: 2.4986 Acc: 0.4640
0m 30s
Epoch 36/199
----------
LR 0.001
train Loss: 0.3489 Acc: 0.8942
val Loss: 2.4348 Acc: 0.4755
0m 30s
Epoch 37/199
----------
LR 0.001
train Loss: 0.3248 Acc: 0.9019
val Loss: 2.5142 Acc: 0.4690
0m 31s
Epoch 38/199
----------
LR 0.001
train Loss: 0.3757 Acc: 0.8854
val Loss: 2.4739 Acc: 0.4740
0m 31s
Epoch 39/199
----------
LR 0.001
train Loss: 0.3561 Acc: 0.8919
val Loss: 2.5114 Acc: 0.4640
0m 31s
Epoch 40/199
----------
LR 0.001
train Loss: 0.3510 Acc: 0.8918
val Loss: 2.5803 Acc: 0.4589
0m 31s
Epoch 41/199
----------
LR 0.001
train Loss: 0.3401 Acc: 0.8960
val Loss: 2.5609 Acc: 0.4660
0m 31s
Epoch 42/199
----------
LR 0.001
train Loss: 0.3657 Acc: 0.8869
val Loss: 2.5080 Acc: 0.4687
0m 31s
Epoch 43/199
----------
LR 0.001
train Loss: 0.3379 Acc: 0.8963
val Loss: 2.5143 Acc: 0.4641
0m 30s
Epoch 44/199
----------
LR 0.001
train Loss: 0.3629 Acc: 0.8879
val Loss: 2.4982 Acc: 0.4681
0m 31s
Epoch 45/199
----------
LR 0.001
train Loss: 0.3503 Acc: 0.8928
val Loss: 2.4582 Acc: 0.4748
0m 30s
Epoch 46/199
----------
LR 0.001
train Loss: 0.3364 Acc: 0.8980
val Loss: 2.5324 Acc: 0.4617
0m 30s
Epoch 47/199
----------
LR 0.001
train Loss: 0.3249 Acc: 0.9006
val Loss: 2.5224 Acc: 0.4670
0m 31s
Epoch 48/199
----------
LR 0.001
train Loss: 0.3224 Acc: 0.9011
val Loss: 2.5503 Acc: 0.4719
0m 30s
Epoch 49/199
----------
LR 0.001
train Loss: 0.3300 Acc: 0.8983
val Loss: 2.5311 Acc: 0.4632
0m 31s
Epoch 50/199
----------
LR 0.001
train Loss: 0.3439 Acc: 0.8954
val Loss: 2.5114 Acc: 0.4707
0m 30s
Epoch 51/199
----------
LR 0.001
train Loss: 0.3319 Acc: 0.8989
val Loss: 2.5198 Acc: 0.4683
0m 31s
Epoch 52/199
----------
LR 0.001
train Loss: 0.3077 Acc: 0.9075
val Loss: 2.5251 Acc: 0.4747
0m 30s
Epoch 53/199
----------
LR 0.001
train Loss: 0.3163 Acc: 0.9036
val Loss: 2.5675 Acc: 0.4562
0m 31s
Epoch 54/199
----------
LR 0.001
train Loss: 0.3204 Acc: 0.9034
val Loss: 2.4764 Acc: 0.4706
0m 30s
Epoch 55/199
----------
LR 0.001
train Loss: 0.3175 Acc: 0.9029
val Loss: 2.5654 Acc: 0.4630
0m 30s
Epoch 56/199
----------
LR 0.001
train Loss: 0.3379 Acc: 0.8965
val Loss: 2.6357 Acc: 0.4610
0m 31s
Epoch 57/199
----------
LR 0.001
train Loss: 0.3290 Acc: 0.8997
val Loss: 2.5495 Acc: 0.4700
0m 30s
Epoch 58/199
----------
LR 0.001
train Loss: 0.3172 Acc: 0.9017
val Loss: 2.4540 Acc: 0.4806
saving best model
best_acc 0.4806
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 59/199
----------
LR 0.001
train Loss: 0.3178 Acc: 0.9028
val Loss: 2.5417 Acc: 0.4704
0m 30s
Epoch 60/199
----------
LR 0.0002
train Loss: 0.0913 Acc: 0.9782
val Loss: 2.0617 Acc: 0.5489
saving best model
best_acc 0.5489
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 61/199
----------
LR 0.0002
train Loss: 0.0174 Acc: 0.9991
val Loss: 2.0431 Acc: 0.5531
saving best model
best_acc 0.5531
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 62/199
----------
LR 0.0002
train Loss: 0.0121 Acc: 0.9994
val Loss: 2.0363 Acc: 0.5536
saving best model
best_acc 0.5536
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 63/199
----------
LR 0.0002
train Loss: 0.0098 Acc: 0.9994
val Loss: 2.0276 Acc: 0.5534
0m 31s
Epoch 64/199
----------
LR 0.0002
train Loss: 0.0086 Acc: 0.9995
val Loss: 2.0118 Acc: 0.5538
saving best model
best_acc 0.5538
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 65/199
----------
LR 0.0002
train Loss: 0.0077 Acc: 0.9996
val Loss: 2.0055 Acc: 0.5543
saving best model
best_acc 0.5543
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 66/199
----------
LR 0.0002
train Loss: 0.0075 Acc: 0.9995
val Loss: 1.9962 Acc: 0.5544
saving best model
best_acc 0.5544
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 67/199
----------
LR 0.0002
train Loss: 0.0071 Acc: 0.9995
val Loss: 1.9814 Acc: 0.5568
saving best model
best_acc 0.5568
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 68/199
----------
LR 0.0002
train Loss: 0.0069 Acc: 0.9995
val Loss: 1.9771 Acc: 0.5548
0m 30s
Epoch 69/199
----------
LR 0.0002
train Loss: 0.0069 Acc: 0.9995
val Loss: 1.9648 Acc: 0.5574
saving best model
best_acc 0.5574
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 70/199
----------
LR 0.0002
train Loss: 0.0069 Acc: 0.9995
val Loss: 1.9511 Acc: 0.5568
0m 30s
Epoch 71/199
----------
LR 0.0002
train Loss: 0.0068 Acc: 0.9996
val Loss: 1.9440 Acc: 0.5575
saving best model
best_acc 0.5575
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 72/199
----------
LR 0.0002
train Loss: 0.0067 Acc: 0.9996
val Loss: 1.9317 Acc: 0.5581
saving best model
best_acc 0.5581
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 73/199
----------
LR 0.0002
train Loss: 0.0067 Acc: 0.9996
val Loss: 1.9338 Acc: 0.5589
saving best model
best_acc 0.5589
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 74/199
----------
LR 0.0002
train Loss: 0.0067 Acc: 0.9997
val Loss: 1.9230 Acc: 0.5582
0m 31s
Epoch 75/199
----------
LR 0.0002
train Loss: 0.0067 Acc: 0.9997
val Loss: 1.9154 Acc: 0.5592
saving best model
best_acc 0.5592
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 76/199
----------
LR 0.0002
train Loss: 0.0069 Acc: 0.9996
val Loss: 1.9171 Acc: 0.5565
0m 31s
Epoch 77/199
----------
LR 0.0002
train Loss: 0.0071 Acc: 0.9995
val Loss: 1.9084 Acc: 0.5585
0m 31s
Epoch 78/199
----------
LR 0.0002
train Loss: 0.0070 Acc: 0.9996
val Loss: 1.9087 Acc: 0.5560
0m 31s
Epoch 79/199
----------
LR 0.0002
train Loss: 0.0069 Acc: 0.9996
val Loss: 1.8996 Acc: 0.5593
saving best model
best_acc 0.5593
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 80/199
----------
LR 0.0002
train Loss: 0.0071 Acc: 0.9996
val Loss: 1.8913 Acc: 0.5583
0m 31s
Epoch 81/199
----------
LR 0.0002
train Loss: 0.0072 Acc: 0.9996
val Loss: 1.8915 Acc: 0.5582
0m 31s
Epoch 82/199
----------
LR 0.0002
train Loss: 0.0074 Acc: 0.9996
val Loss: 1.8866 Acc: 0.5580
0m 31s
Epoch 83/199
----------
LR 0.0002
train Loss: 0.0073 Acc: 0.9996
val Loss: 1.8855 Acc: 0.5590
0m 30s
Epoch 84/199
----------
LR 0.0002
train Loss: 0.0073 Acc: 0.9997
val Loss: 1.8889 Acc: 0.5594
saving best model
best_acc 0.5594
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 85/199
----------
LR 0.0002
train Loss: 0.0072 Acc: 0.9997
val Loss: 1.8785 Acc: 0.5612
saving best model
best_acc 0.5612
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 86/199
----------
LR 0.0002
train Loss: 0.0072 Acc: 0.9997
val Loss: 1.8797 Acc: 0.5616
saving best model
best_acc 0.5616
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 87/199
----------
LR 0.0002
train Loss: 0.0073 Acc: 0.9997
val Loss: 1.8851 Acc: 0.5590
0m 31s
Epoch 88/199
----------
LR 0.0002
train Loss: 0.0073 Acc: 0.9997
val Loss: 1.8814 Acc: 0.5600
0m 31s
Epoch 89/199
----------
LR 0.0002
train Loss: 0.0074 Acc: 0.9996
val Loss: 1.8849 Acc: 0.5587
0m 30s
Epoch 90/199
----------
LR 0.0002
train Loss: 0.0075 Acc: 0.9996
val Loss: 1.8794 Acc: 0.5590
0m 31s
Epoch 91/199
----------
LR 0.0002
train Loss: 0.0076 Acc: 0.9995
val Loss: 1.8791 Acc: 0.5601
0m 31s
Epoch 92/199
----------
LR 0.0002
train Loss: 0.0077 Acc: 0.9996
val Loss: 1.8810 Acc: 0.5592
0m 30s
Epoch 93/199
----------
LR 0.0002
train Loss: 0.0074 Acc: 0.9997
val Loss: 1.8798 Acc: 0.5585
0m 31s
Epoch 94/199
----------
LR 0.0002
train Loss: 0.0074 Acc: 0.9998
val Loss: 1.8879 Acc: 0.5604
0m 31s
Epoch 95/199
----------
LR 0.0002
train Loss: 0.0076 Acc: 0.9996
val Loss: 1.8818 Acc: 0.5592
0m 30s
Epoch 96/199
----------
LR 0.0002
train Loss: 0.0075 Acc: 0.9996
val Loss: 1.8874 Acc: 0.5592
0m 31s
Epoch 97/199
----------
LR 0.0002
train Loss: 0.0076 Acc: 0.9997
val Loss: 1.8849 Acc: 0.5603
0m 31s
Epoch 98/199
----------
LR 0.0002
train Loss: 0.0075 Acc: 0.9997
val Loss: 1.8932 Acc: 0.5615
0m 31s
Epoch 99/199
----------
LR 0.0002
train Loss: 0.0074 Acc: 0.9997
val Loss: 1.8919 Acc: 0.5603
0m 30s
Epoch 100/199
----------
LR 0.0002
train Loss: 0.0076 Acc: 0.9996
val Loss: 1.8928 Acc: 0.5583
0m 31s
Epoch 101/199
----------
LR 0.0002
train Loss: 0.0078 Acc: 0.9997
val Loss: 1.9001 Acc: 0.5600
0m 30s
Epoch 102/199
----------
LR 0.0002
train Loss: 0.0075 Acc: 0.9997
val Loss: 1.9049 Acc: 0.5593
0m 31s
Epoch 103/199
----------
LR 0.0002
train Loss: 0.0074 Acc: 0.9996
val Loss: 1.9002 Acc: 0.5600
0m 30s
Epoch 104/199
----------
LR 0.0002
train Loss: 0.0075 Acc: 0.9997
val Loss: 1.9115 Acc: 0.5597
0m 30s
Epoch 105/199
----------
LR 0.0002
train Loss: 0.0078 Acc: 0.9996
val Loss: 1.9110 Acc: 0.5585
0m 31s
Epoch 106/199
----------
LR 0.0002
train Loss: 0.0076 Acc: 0.9996
val Loss: 1.9097 Acc: 0.5614
0m 31s
Epoch 107/199
----------
LR 0.0002
train Loss: 0.0079 Acc: 0.9996
val Loss: 1.9167 Acc: 0.5598
0m 31s
Epoch 108/199
----------
LR 0.0002
train Loss: 0.0078 Acc: 0.9996
val Loss: 1.9242 Acc: 0.5603
0m 31s
Epoch 109/199
----------
LR 0.0002
train Loss: 0.0077 Acc: 0.9996
val Loss: 1.9260 Acc: 0.5583
0m 30s
Epoch 110/199
----------
LR 0.0002
train Loss: 0.0076 Acc: 0.9996
val Loss: 1.9279 Acc: 0.5610
0m 31s
Epoch 111/199
----------
LR 0.0002
train Loss: 0.0075 Acc: 0.9996
val Loss: 1.9289 Acc: 0.5618
saving best model
best_acc 0.5618
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 112/199
----------
LR 0.0002
train Loss: 0.0074 Acc: 0.9997
val Loss: 1.9333 Acc: 0.5599
0m 30s
Epoch 113/199
----------
LR 0.0002
train Loss: 0.0075 Acc: 0.9996
val Loss: 1.9360 Acc: 0.5591
0m 31s
Epoch 114/199
----------
LR 0.0002
train Loss: 0.0079 Acc: 0.9996
val Loss: 1.9446 Acc: 0.5569
0m 31s
Epoch 115/199
----------
LR 0.0002
train Loss: 0.0076 Acc: 0.9997
val Loss: 1.9521 Acc: 0.5585
0m 30s
Epoch 116/199
----------
LR 0.0002
train Loss: 0.0074 Acc: 0.9997
val Loss: 1.9533 Acc: 0.5604
0m 31s
Epoch 117/199
----------
LR 0.0002
train Loss: 0.0074 Acc: 0.9996
val Loss: 1.9612 Acc: 0.5615
0m 31s
Epoch 118/199
----------
LR 0.0002
train Loss: 0.0073 Acc: 0.9997
val Loss: 1.9696 Acc: 0.5595
0m 31s
Epoch 119/199
----------
LR 0.0002
train Loss: 0.0074 Acc: 0.9997
val Loss: 1.9786 Acc: 0.5589
0m 30s
Epoch 120/199
----------
LR 4e-05
train Loss: 0.0072 Acc: 0.9997
val Loss: 1.9747 Acc: 0.5580
0m 30s
Epoch 121/199
----------
LR 4e-05
train Loss: 0.0072 Acc: 0.9998
val Loss: 1.9709 Acc: 0.5619
saving best model
best_acc 0.5619
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 122/199
----------
LR 4e-05
train Loss: 0.0070 Acc: 0.9998
val Loss: 1.9694 Acc: 0.5585
0m 31s
Epoch 123/199
----------
LR 4e-05
train Loss: 0.0072 Acc: 0.9998
val Loss: 1.9717 Acc: 0.5584
0m 31s
Epoch 124/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9998
val Loss: 1.9719 Acc: 0.5606
0m 30s
Epoch 125/199
----------
LR 4e-05
train Loss: 0.0070 Acc: 0.9998
val Loss: 1.9716 Acc: 0.5604
0m 30s
Epoch 126/199
----------
LR 4e-05
train Loss: 0.0070 Acc: 0.9998
val Loss: 1.9726 Acc: 0.5596
0m 31s
Epoch 127/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9997
val Loss: 1.9715 Acc: 0.5591
0m 31s
Epoch 128/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9998
val Loss: 1.9788 Acc: 0.5591
0m 30s
Epoch 129/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9998
val Loss: 1.9829 Acc: 0.5591
0m 30s
Epoch 130/199
----------
LR 4e-05
train Loss: 0.0070 Acc: 0.9997
val Loss: 1.9761 Acc: 0.5603
0m 31s
Epoch 131/199
----------
LR 4e-05
train Loss: 0.0070 Acc: 0.9998
val Loss: 1.9740 Acc: 0.5594
0m 31s
Epoch 132/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9998
val Loss: 1.9807 Acc: 0.5595
0m 31s
Epoch 133/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9998
val Loss: 1.9817 Acc: 0.5610
0m 31s
Epoch 134/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9998
val Loss: 1.9825 Acc: 0.5601
0m 31s
Epoch 135/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9997
val Loss: 1.9808 Acc: 0.5626
saving best model
best_acc 0.5626
Model saved to results/cifar100/2021-12-02-10-20-05__densenet121_8077
0m 31s
Epoch 136/199
----------
LR 4e-05
train Loss: 0.0070 Acc: 0.9997
val Loss: 1.9847 Acc: 0.5594
0m 30s
Epoch 137/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9998
val Loss: 1.9830 Acc: 0.5605
0m 30s
Epoch 138/199
----------
LR 4e-05
train Loss: 0.0070 Acc: 0.9997
val Loss: 1.9832 Acc: 0.5573
0m 31s
Epoch 139/199
----------
LR 4e-05
train Loss: 0.0070 Acc: 0.9998
val Loss: 1.9835 Acc: 0.5595
0m 30s
Epoch 140/199
----------
LR 4e-05
train Loss: 0.0070 Acc: 0.9997
val Loss: 1.9849 Acc: 0.5574
0m 30s
Epoch 141/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9998
val Loss: 1.9871 Acc: 0.5609
0m 31s
Epoch 142/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9997
val Loss: 1.9908 Acc: 0.5578
0m 30s
Epoch 143/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9998
val Loss: 1.9864 Acc: 0.5602
0m 31s
Epoch 144/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9997
val Loss: 1.9920 Acc: 0.5585
0m 30s
Epoch 145/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9997
val Loss: 1.9918 Acc: 0.5584
0m 31s
Epoch 146/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9998
val Loss: 1.9883 Acc: 0.5587
0m 30s
Epoch 147/199
----------
LR 4e-05
train Loss: 0.0070 Acc: 0.9998
val Loss: 1.9936 Acc: 0.5593
0m 31s
Epoch 148/199
----------
LR 4e-05
train Loss: 0.0072 Acc: 0.9997
val Loss: 1.9923 Acc: 0.5582
0m 31s
Epoch 149/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9997
val Loss: 1.9959 Acc: 0.5577
0m 31s
Epoch 150/199
----------
LR 4e-05
train Loss: 0.0070 Acc: 0.9998
val Loss: 1.9932 Acc: 0.5576
0m 31s
Epoch 151/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9998
val Loss: 1.9995 Acc: 0.5579
0m 30s
Epoch 152/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9997
val Loss: 1.9964 Acc: 0.5595
0m 31s
Epoch 153/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9997
val Loss: 2.0002 Acc: 0.5611
0m 31s
Epoch 154/199
----------
LR 4e-05
train Loss: 0.0072 Acc: 0.9998
val Loss: 1.9979 Acc: 0.5578
0m 30s
Epoch 155/199
----------
LR 4e-05
train Loss: 0.0070 Acc: 0.9998
val Loss: 1.9953 Acc: 0.5565
0m 30s
Epoch 156/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9998
val Loss: 2.0054 Acc: 0.5587
0m 30s
Epoch 157/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9998
val Loss: 2.0005 Acc: 0.5589
0m 31s
Epoch 158/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9998
val Loss: 2.0012 Acc: 0.5596
0m 31s
Epoch 159/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9998
val Loss: 2.0006 Acc: 0.5572
0m 31s
Epoch 160/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9998
val Loss: 2.0047 Acc: 0.5574
0m 30s
Epoch 161/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9998
val Loss: 2.0070 Acc: 0.5587
0m 31s
Epoch 162/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9998
val Loss: 2.0095 Acc: 0.5592
0m 31s
Epoch 163/199
----------
LR 4e-05
train Loss: 0.0070 Acc: 0.9998
val Loss: 2.0023 Acc: 0.5598
0m 31s
Epoch 164/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9998
val Loss: 2.0053 Acc: 0.5584
0m 30s
Epoch 165/199
----------
LR 4e-05
train Loss: 0.0072 Acc: 0.9997
val Loss: 2.0084 Acc: 0.5568
0m 31s
Epoch 166/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9998
val Loss: 2.0106 Acc: 0.5604
0m 30s
Epoch 167/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9998
val Loss: 2.0117 Acc: 0.5569
0m 31s
Epoch 168/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9998
val Loss: 2.0117 Acc: 0.5584
0m 30s
Epoch 169/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9998
val Loss: 2.0078 Acc: 0.5594
0m 30s
Epoch 170/199
----------
LR 4e-05
train Loss: 0.0072 Acc: 0.9997
val Loss: 2.0126 Acc: 0.5579
0m 31s
Epoch 171/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9998
val Loss: 2.0114 Acc: 0.5591
0m 31s
Epoch 172/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9998
val Loss: 2.0127 Acc: 0.5588
0m 30s
Epoch 173/199
----------
LR 4e-05
train Loss: 0.0072 Acc: 0.9998
val Loss: 2.0098 Acc: 0.5611
0m 31s
Epoch 174/199
----------
LR 4e-05
train Loss: 0.0072 Acc: 0.9997
val Loss: 2.0118 Acc: 0.5605
0m 31s
Epoch 175/199
----------
LR 4e-05
train Loss: 0.0070 Acc: 0.9997
val Loss: 2.0083 Acc: 0.5601
0m 30s
Epoch 176/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9997
val Loss: 2.0144 Acc: 0.5589
0m 30s
Epoch 177/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9998
val Loss: 2.0151 Acc: 0.5576
0m 31s
Epoch 178/199
----------
LR 4e-05
train Loss: 0.0071 Acc: 0.9997
val Loss: 2.0195 Acc: 0.5592
0m 31s
Epoch 179/199
----------
LR 4e-05
train Loss: 0.0072 Acc: 0.9997
val Loss: 2.0241 Acc: 0.5570
0m 31s
Epoch 180/199
----------
LR 8.000000000000001e-06
train Loss: 0.0070 Acc: 0.9998
val Loss: 2.0182 Acc: 0.5568
0m 31s
Epoch 181/199
----------
LR 8.000000000000001e-06
train Loss: 0.0071 Acc: 0.9998
val Loss: 2.0206 Acc: 0.5597
0m 31s
Epoch 182/199
----------
LR 8.000000000000001e-06
train Loss: 0.0070 Acc: 0.9998
val Loss: 2.0176 Acc: 0.5585
0m 31s
Epoch 183/199
----------
LR 8.000000000000001e-06
train Loss: 0.0070 Acc: 0.9998
val Loss: 2.0181 Acc: 0.5597
0m 30s
Epoch 184/199
----------
LR 8.000000000000001e-06
train Loss: 0.0070 Acc: 0.9998
val Loss: 2.0126 Acc: 0.5588
0m 31s
Epoch 185/199
----------
LR 8.000000000000001e-06
train Loss: 0.0070 Acc: 0.9998
val Loss: 2.0115 Acc: 0.5617
0m 31s
Epoch 186/199
----------
LR 8.000000000000001e-06
train Loss: 0.0070 Acc: 0.9998
val Loss: 2.0183 Acc: 0.5579
0m 30s
Epoch 187/199
----------
LR 8.000000000000001e-06
train Loss: 0.0071 Acc: 0.9998
val Loss: 2.0158 Acc: 0.5575
0m 31s
Epoch 188/199
----------
LR 8.000000000000001e-06
train Loss: 0.0070 Acc: 0.9998
val Loss: 2.0196 Acc: 0.5584
0m 30s
Epoch 189/199
----------
LR 8.000000000000001e-06
train Loss: 0.0070 Acc: 0.9997
val Loss: 2.0205 Acc: 0.5578
0m 31s
Epoch 190/199
----------
LR 8.000000000000001e-06
train Loss: 0.0070 Acc: 0.9998
val Loss: 2.0155 Acc: 0.5585
0m 31s
Epoch 191/199
----------
LR 8.000000000000001e-06
train Loss: 0.0071 Acc: 0.9998
val Loss: 2.0202 Acc: 0.5599
0m 31s
Epoch 192/199
----------
LR 8.000000000000001e-06
train Loss: 0.0071 Acc: 0.9998
val Loss: 2.0236 Acc: 0.5578
0m 30s
Epoch 193/199
----------
LR 8.000000000000001e-06
train Loss: 0.0070 Acc: 0.9999
val Loss: 2.0176 Acc: 0.5598
0m 31s
Epoch 194/199
----------
LR 8.000000000000001e-06
train Loss: 0.0070 Acc: 0.9998
val Loss: 2.0176 Acc: 0.5585
0m 31s
Epoch 195/199
----------
LR 8.000000000000001e-06
train Loss: 0.0070 Acc: 0.9999
val Loss: 2.0197 Acc: 0.5608
0m 31s
Epoch 196/199
----------
LR 8.000000000000001e-06
train Loss: 0.0070 Acc: 0.9998
val Loss: 2.0220 Acc: 0.5586
0m 30s
Epoch 197/199
----------
LR 8.000000000000001e-06
train Loss: 0.0070 Acc: 0.9998
val Loss: 2.0157 Acc: 0.5601
0m 30s
Epoch 198/199
----------
LR 8.000000000000001e-06
train Loss: 0.0070 Acc: 0.9999
val Loss: 2.0184 Acc: 0.5584
0m 31s
Epoch 199/199
----------
LR 8.000000000000001e-06
train Loss: 0.0071 Acc: 0.9998
val Loss: 2.0262 Acc: 0.5575
0m 31s
Best val acc: 0.562600
